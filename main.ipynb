{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/raychannudam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/raychannudam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/raychannudam/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/raychannudam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans(\"\",\"\",string.punctuation)\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "STOP_WORDS = stopwords.words('english')\n",
    "VOCAB_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read negative and positive reviews\n",
    "with open('negative-reviews.txt') as file:\n",
    "    negative_content = file.readlines()\n",
    "    file.close()\n",
    "with open('positive-reviews.txt') as file:\n",
    "    positive_content = file.readlines()\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read negative and positive words\n",
    "with open('negative-words.txt', encoding='latin-1') as file:\n",
    "    negative_words = file.readlines()\n",
    "    file.close()\n",
    "with open('positive-words.txt') as file:\n",
    "    positive_words = file.readlines()\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create removeNewline function\n",
    "def removeNewline(content):\n",
    "    return re.sub(\"\\n\", \"\", content)\n",
    "\n",
    "# convert to lowercase\n",
    "def toLower(content):\n",
    "    return content.lower()\n",
    "\n",
    "# remove punctuation\n",
    "def removePunctuation(content):\n",
    "    return content.translate(translator)\n",
    "\n",
    "# word lemmatization\n",
    "def wordLemmatization(content):\n",
    "    words = nltk.word_tokenize(content)\n",
    "    tagged_words = pos_tag(words)\n",
    "    lemma = [lemmatizer.lemmatize(word, \"v\") if pos in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'] else word for word, pos in tagged_words]\n",
    "    return \" \".join(lemma)\n",
    "\n",
    "# remove single character\n",
    "def removeSingleChar(content):\n",
    "    return re.sub(r'\\b\\w{1}\\b', '', content)\n",
    "\n",
    "# remove pronounce\n",
    "def removePronouns(content):\n",
    "    words = nltk.word_tokenize(content)\n",
    "    tagged_words = pos_tag(words)\n",
    "    non_pronounces = [word for word, pos in tagged_words if pos not in ['PRP', 'PRP$', 'WP', 'WP$']]\n",
    "    return \" \".join(non_pronounces)\n",
    "\n",
    "# remove stopwords\n",
    "def removeStopwords(content):\n",
    "  words = []\n",
    "  words = content.split(\" \")\n",
    "  all_words = set(words)\n",
    "  common_words = set(words).intersection(set(STOP_WORDS))\n",
    "  uncommon_words = list(all_words - common_words)\n",
    "  return \" \".join(uncommon_words)\n",
    "\n",
    "# remove common\n",
    "def removeCommon(content, common_words):\n",
    "  words = set(content.split(\" \"))\n",
    "  common_words = set(common_words)\n",
    "  found_common_words = list(common_words.intersection(words))\n",
    "  uncommon_words = [word for word in content.split(\" \") if word not in found_common_words]\n",
    "  return \" \".join(uncommon_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(content):\n",
    "    content = removeNewline(content)\n",
    "    content = toLower(content)\n",
    "    content = removePunctuation(content)\n",
    "    content = wordLemmatization(content)\n",
    "    content = removePronouns(content)\n",
    "    # content = removeStopwords(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = []\n",
    "contents = [negative_content, positive_content, negative_words, positive_words]\n",
    "for content in contents:\n",
    "    temp = [preprocessing(sentence) for sentence in content]\n",
    "    temps.append(temp)\n",
    "cleaned_negative_content = temps[0]\n",
    "cleaned_positive_content = temps[1]\n",
    "cleaned_negative_words = temps[2]\n",
    "cleaned_positive_words = temps[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = []\n",
    "contents = [negative_content, positive_content, negative_words, positive_words]\n",
    "for content in contents:\n",
    "    temp = [removeNewline(sentence) for sentence in content]\n",
    "    temps.append(temp)\n",
    "\n",
    "temps = []\n",
    "for content in contents:\n",
    "    temp = [toLower(sentence) for sentence in content]\n",
    "    temps.append(temp)\n",
    "negative_content = temps[0]\n",
    "positive_content = temps[1]\n",
    "negative_words = temps[2]\n",
    "positive_words = temps[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common words: ['have', 'very', 'be', 'to', 'of', 'the', 'for', 'in', 'on', 'and', 'can', 'with', 'too', 'a']\n",
      "Total number of unique_words = 16538\n"
     ]
    }
   ],
   "source": [
    "# checking common_words and unique vocab\n",
    "\n",
    "tokens = []\n",
    "contents = [cleaned_negative_content, cleaned_positive_content, cleaned_negative_words, cleaned_positive_words]\n",
    "for content in contents:\n",
    "    temp = [nltk.word_tokenize(sentence) for sentence in content]\n",
    "    tokens.append(temp)\n",
    "flat_unigrams = [ t for token_list in tokens for token in token_list for t in token]\n",
    "fdist_unigrams = FreqDist(token for token in flat_unigrams)\n",
    "common_words = [word for word in list(set([item[0] for item in fdist_unigrams.most_common(50)]).intersection(STOP_WORDS)) if word != \"no\" and word != \"not\" and word != \"but\"]\n",
    "print(f\"Common words: {common_words}\")\n",
    "print(f\"Total number of unique_words = {fdist_unigrams.B()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"common_word.txt\", \"w\") as f:\n",
    "    for word in common_words:\n",
    "        f.write(f\"{word}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove top 50 common words, where are in STOP_WORDS list\n",
    "\n",
    "temps = []\n",
    "contents = [cleaned_negative_content, cleaned_positive_content, cleaned_negative_words, cleaned_positive_words]\n",
    "for content in contents:\n",
    "    temp = [removeCommon(sentence, common_words) for sentence in content]\n",
    "    temps.append(temp)\n",
    "cleaned_negative_content = temps[0]\n",
    "cleaned_positive_content = temps[1]\n",
    "cleaned_negative_words = temps[2]\n",
    "cleaned_positive_words = temps[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>size, size, ans size.\\n</td>\n",
       "      <td>size size ans size</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent quality, speedy printing, low cost\\n</td>\n",
       "      <td>excellent quality speedy print low cost</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cheap, good quality, small size\\n</td>\n",
       "      <td>cheap good quality small size</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attractive design, satisfying features, the ba...</td>\n",
       "      <td>attractive design satisfying feature backlight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty much has every feature you could possib...</td>\n",
       "      <td>pretty much every feature could possibly need ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0                            size, size, ans size.\\n   \n",
       "1     excellent quality, speedy printing, low cost\\n   \n",
       "2                  cheap, good quality, small size\\n   \n",
       "3  attractive design, satisfying features, the ba...   \n",
       "4  pretty much has every feature you could possib...   \n",
       "\n",
       "                                      cleaned_review  category  \n",
       "0                                 size size ans size         1  \n",
       "1            excellent quality speedy print low cost         1  \n",
       "2                      cheap good quality small size         1  \n",
       "3     attractive design satisfying feature backlight         1  \n",
       "4  pretty much every feature could possibly need ...         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df = pd.DataFrame({\n",
    "    \"review\": positive_content,\n",
    "    \"cleaned_review\": cleaned_positive_content,\n",
    "    \"category\": 1\n",
    "})\n",
    "negative_df = pd.DataFrame({\n",
    "    \"review\": negative_content,\n",
    "    \"cleaned_review\": cleaned_negative_content,\n",
    "    \"category\": 0\n",
    "})\n",
    "df = pd.concat([positive_df, negative_df], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>category</th>\n",
       "      <th>pos_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>size, size, ans size.\\n</td>\n",
       "      <td>size size ans size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent quality, speedy printing, low cost\\n</td>\n",
       "      <td>excellent quality speedy print low cost</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cheap, good quality, small size\\n</td>\n",
       "      <td>cheap good quality small size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attractive design, satisfying features, the ba...</td>\n",
       "      <td>attractive design satisfying feature backlight</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty much has every feature you could possib...</td>\n",
       "      <td>pretty much every feature could possibly need ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0                            size, size, ans size.\\n   \n",
       "1     excellent quality, speedy printing, low cost\\n   \n",
       "2                  cheap, good quality, small size\\n   \n",
       "3  attractive design, satisfying features, the ba...   \n",
       "4  pretty much has every feature you could possib...   \n",
       "\n",
       "                                      cleaned_review  category  pos_count  \n",
       "0                                 size size ans size         1          0  \n",
       "1            excellent quality speedy print low cost         1          0  \n",
       "2                      cheap good quality small size         1          0  \n",
       "3     attractive design satisfying feature backlight         1          0  \n",
       "4  pretty much every feature could possibly need ...         1          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pos_count'] = df['review'].apply(lambda x: len([word for word in x.split() if word in positive_words]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>category</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>size, size, ans size.\\n</td>\n",
       "      <td>size size ans size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent quality, speedy printing, low cost\\n</td>\n",
       "      <td>excellent quality speedy print low cost</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cheap, good quality, small size\\n</td>\n",
       "      <td>cheap good quality small size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attractive design, satisfying features, the ba...</td>\n",
       "      <td>attractive design satisfying feature backlight</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty much has every feature you could possib...</td>\n",
       "      <td>pretty much every feature could possibly need ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0                            size, size, ans size.\\n   \n",
       "1     excellent quality, speedy printing, low cost\\n   \n",
       "2                  cheap, good quality, small size\\n   \n",
       "3  attractive design, satisfying features, the ba...   \n",
       "4  pretty much has every feature you could possib...   \n",
       "\n",
       "                                      cleaned_review  category  pos_count  \\\n",
       "0                                 size size ans size         1          0   \n",
       "1            excellent quality speedy print low cost         1          0   \n",
       "2                      cheap good quality small size         1          0   \n",
       "3     attractive design satisfying feature backlight         1          0   \n",
       "4  pretty much every feature could possibly need ...         1          0   \n",
       "\n",
       "   neg_count  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['neg_count'] = df['review'].apply(lambda x: len([word for word in x.split() if word in negative_words]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>category</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>contain_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>size, size, ans size.\\n</td>\n",
       "      <td>size size ans size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent quality, speedy printing, low cost\\n</td>\n",
       "      <td>excellent quality speedy print low cost</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cheap, good quality, small size\\n</td>\n",
       "      <td>cheap good quality small size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attractive design, satisfying features, the ba...</td>\n",
       "      <td>attractive design satisfying feature backlight</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty much has every feature you could possib...</td>\n",
       "      <td>pretty much every feature could possibly need ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0                            size, size, ans size.\\n   \n",
       "1     excellent quality, speedy printing, low cost\\n   \n",
       "2                  cheap, good quality, small size\\n   \n",
       "3  attractive design, satisfying features, the ba...   \n",
       "4  pretty much has every feature you could possib...   \n",
       "\n",
       "                                      cleaned_review  category  pos_count  \\\n",
       "0                                 size size ans size         1          0   \n",
       "1            excellent quality speedy print low cost         1          0   \n",
       "2                      cheap good quality small size         1          0   \n",
       "3     attractive design satisfying feature backlight         1          0   \n",
       "4  pretty much every feature could possibly need ...         1          0   \n",
       "\n",
       "   neg_count  contain_no  \n",
       "0          0           0  \n",
       "1          0           0  \n",
       "2          0           0  \n",
       "3          0           0  \n",
       "4          0           0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['contain_no'] = df['review'].apply(lambda x: 1 if 'no' in x.split() else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>category</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>contain_no</th>\n",
       "      <th>count_1_2_pron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>size, size, ans size.\\n</td>\n",
       "      <td>size size ans size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent quality, speedy printing, low cost\\n</td>\n",
       "      <td>excellent quality speedy print low cost</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cheap, good quality, small size\\n</td>\n",
       "      <td>cheap good quality small size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attractive design, satisfying features, the ba...</td>\n",
       "      <td>attractive design satisfying feature backlight</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty much has every feature you could possib...</td>\n",
       "      <td>pretty much every feature could possibly need ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0                            size, size, ans size.\\n   \n",
       "1     excellent quality, speedy printing, low cost\\n   \n",
       "2                  cheap, good quality, small size\\n   \n",
       "3  attractive design, satisfying features, the ba...   \n",
       "4  pretty much has every feature you could possib...   \n",
       "\n",
       "                                      cleaned_review  category  pos_count  \\\n",
       "0                                 size size ans size         1          0   \n",
       "1            excellent quality speedy print low cost         1          0   \n",
       "2                      cheap good quality small size         1          0   \n",
       "3     attractive design satisfying feature backlight         1          0   \n",
       "4  pretty much every feature could possibly need ...         1          0   \n",
       "\n",
       "   neg_count  contain_no  count_1_2_pron  \n",
       "0          0           0               0  \n",
       "1          0           0               0  \n",
       "2          0           0               0  \n",
       "3          0           0               0  \n",
       "4          0           0               1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['count_1_2_pron'] = df['review'].apply(lambda x: len([word for word in x.split() if word in ['i', 'me', 'my', 'you', 'your']]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>category</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>contain_no</th>\n",
       "      <th>count_1_2_pron</th>\n",
       "      <th>contain_!</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>size, size, ans size.\\n</td>\n",
       "      <td>size size ans size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent quality, speedy printing, low cost\\n</td>\n",
       "      <td>excellent quality speedy print low cost</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cheap, good quality, small size\\n</td>\n",
       "      <td>cheap good quality small size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attractive design, satisfying features, the ba...</td>\n",
       "      <td>attractive design satisfying feature backlight</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty much has every feature you could possib...</td>\n",
       "      <td>pretty much every feature could possibly need ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0                            size, size, ans size.\\n   \n",
       "1     excellent quality, speedy printing, low cost\\n   \n",
       "2                  cheap, good quality, small size\\n   \n",
       "3  attractive design, satisfying features, the ba...   \n",
       "4  pretty much has every feature you could possib...   \n",
       "\n",
       "                                      cleaned_review  category  pos_count  \\\n",
       "0                                 size size ans size         1          0   \n",
       "1            excellent quality speedy print low cost         1          0   \n",
       "2                      cheap good quality small size         1          0   \n",
       "3     attractive design satisfying feature backlight         1          0   \n",
       "4  pretty much every feature could possibly need ...         1          0   \n",
       "\n",
       "   neg_count  contain_no  count_1_2_pron  contain_!  \n",
       "0          0           0               0          0  \n",
       "1          0           0               0          0  \n",
       "2          0           0               0          0  \n",
       "3          0           0               0          0  \n",
       "4          0           0               1          0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['contain_!'] = df['review'].apply(lambda x: 1 if '!' in x.split() else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>category</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>contain_no</th>\n",
       "      <th>count_1_2_pron</th>\n",
       "      <th>contain_!</th>\n",
       "      <th>log_length_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>size, size, ans size.\\n</td>\n",
       "      <td>size size ans size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.135494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent quality, speedy printing, low cost\\n</td>\n",
       "      <td>excellent quality speedy print low cost</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.828641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cheap, good quality, small size\\n</td>\n",
       "      <td>cheap good quality small size</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attractive design, satisfying features, the ba...</td>\n",
       "      <td>attractive design satisfying feature backlight</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.025352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty much has every feature you could possib...</td>\n",
       "      <td>pretty much every feature could possibly need ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.204693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0                            size, size, ans size.\\n   \n",
       "1     excellent quality, speedy printing, low cost\\n   \n",
       "2                  cheap, good quality, small size\\n   \n",
       "3  attractive design, satisfying features, the ba...   \n",
       "4  pretty much has every feature you could possib...   \n",
       "\n",
       "                                      cleaned_review  category  pos_count  \\\n",
       "0                                 size size ans size         1          0   \n",
       "1            excellent quality speedy print low cost         1          0   \n",
       "2                      cheap good quality small size         1          0   \n",
       "3     attractive design satisfying feature backlight         1          0   \n",
       "4  pretty much every feature could possibly need ...         1          0   \n",
       "\n",
       "   neg_count  contain_no  count_1_2_pron  contain_!  log_length_review  \n",
       "0          0           0               0          0           3.135494  \n",
       "1          0           0               0          0           3.828641  \n",
       "2          0           0               0          0           3.496508  \n",
       "3          0           0               0          0           4.025352  \n",
       "4          0           0               1          0           4.204693  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['log_length_review'] = df.review.apply(lambda x: float(np.log(len(x)+1)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.category\n",
    "reviews = df.cleaned_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews, categories, test_size=0.2, stratify=categories, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test: 0.9225\n",
      "Accuracy score on train: 0.9339375\n"
     ]
    }
   ],
   "source": [
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "test_score = accuracy_score(y_test,  clf.predict(X_test))\n",
    "train_score = accuracy_score(y_train, clf.predict(X_train))\n",
    "print(f\"Accuracy score on test: {test_score}\")\n",
    "print(f\"Accuracy score on train: {train_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validaton Score: 0.9201562500000001\n"
     ]
    }
   ],
   "source": [
    "corss_score = cross_val_score(clf, X_train ,y_train, cv=5)\n",
    "print(f\"Cross Validaton Score: {corss_score.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92      4000\n",
      "           1       0.94      0.91      0.92      4000\n",
      "\n",
      "    accuracy                           0.92      8000\n",
      "   macro avg       0.92      0.92      0.92      8000\n",
      "weighted avg       0.92      0.92      0.92      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 13:23:42.620864: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-28 13:23:42.620894: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-28 13:23:42.621964: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-28 13:23:42.627798: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-28 13:23:43.408130: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.drop([\"cleaned_review\", \"review\", \"category\"], axis=1).columns\n",
    "for column in numerical_columns:\n",
    "    df[column] = df[column].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_tf, y_test_tf = train_test_split(\n",
    "    df.drop(['category', 'review'], axis=1), \n",
    "    categories, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=categories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 13:23:45.517422: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-02-28 13:23:45.517447: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: raychannudam\n",
      "2024-02-28 13:23:45.517454: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: raychannudam\n",
      "2024-02-28 13:23:45.517585: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.161.7\n",
      "2024-02-28 13:23:45.517608: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.154.5\n",
      "2024-02-28 13:23:45.517617: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:244] kernel version 535.154.5 does not match DSO version 535.161.7 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TextVectorization(max_tokens=15000, output_mode='int', output_sequence_length=30)\n",
    "vectorizer.adapt(X_train.cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text_tf = vectorizer(X_train.cleaned_review)\n",
    "X_test_text_tf = vectorizer(X_test.cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num_tf = X_train.drop('cleaned_review', axis=1)\n",
    "X_test_num_tf = X_test.drop('cleaned_review', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos_count            float64\n",
       "neg_count            float64\n",
       "contain_no           float64\n",
       "count_1_2_pron       float64\n",
       "contain_!            float64\n",
       "log_length_review    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_tf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          659520    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                33024     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 692544 (2.64 MB)\n",
      "Trainable params: 692544 (2.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_model = tf.keras.models.Sequential()\n",
    "text_model.add(tf.keras.layers.Embedding(input_dim=len(vectorizer.get_vocabulary()), output_dim=64))\n",
    "text_model.add(tf.keras.layers.LSTM(64))\n",
    "text_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                448       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2528 (9.88 KB)\n",
      "Trainable params: 2528 (9.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "numerical_model = tf.keras.models.Sequential()\n",
    "numerical_model.add(tf.keras.layers.Dense(64, input_shape=(X_train_num_tf.shape[1],)))\n",
    "numerical_model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "numerical_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " embedding_input (InputLaye  [(None, None)]               0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " dense_input (InputLayer)    [(None, 6)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 64)             659520    ['embedding_input[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   448       ['dense_input[0][0]']         \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 64)                   33024     ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   2080      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 96)                   0         ['lstm[0][0]',                \n",
      "                                                                     'dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  12416     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 64)                   8256      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    65        ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 715809 (2.73 MB)\n",
      "Trainable params: 715809 (2.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_model_outputs = text_model.outputs[0]\n",
    "numerical_model_outputs = numerical_model.outputs[0]\n",
    "concat_outputs = tf.keras.layers.concatenate([text_model_outputs, numerical_model_outputs])\n",
    "full_dense_outputs_0 = tf.keras.layers.Dense(128, activation='relu')(concat_outputs)\n",
    "full_dense_outputs_1 = tf.keras.layers.Dense(64, activation=\"relu\")(full_dense_outputs_0)\n",
    "final_outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(full_dense_outputs_1)\n",
    "model = tf.keras.models.Model(inputs=[text_model.inputs, numerical_model.inputs], outputs=final_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model_weights/best_model_weights.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 13s 11ms/step - loss: 0.6632 - accuracy: 0.5803 - val_loss: 0.6541 - val_accuracy: 0.5911\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.6570 - accuracy: 0.5896 - val_loss: 0.6546 - val_accuracy: 0.5888\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.4124 - accuracy: 0.7801 - val_loss: 0.2010 - val_accuracy: 0.9231\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1916 - accuracy: 0.9280 - val_loss: 0.1998 - val_accuracy: 0.9289\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1741 - accuracy: 0.9376 - val_loss: 0.1784 - val_accuracy: 0.9320\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1648 - accuracy: 0.9417 - val_loss: 0.1759 - val_accuracy: 0.9327\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1549 - accuracy: 0.9459 - val_loss: 0.1805 - val_accuracy: 0.9331\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1473 - accuracy: 0.9480 - val_loss: 0.1778 - val_accuracy: 0.9351\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1411 - accuracy: 0.9514 - val_loss: 0.1698 - val_accuracy: 0.9304\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1350 - accuracy: 0.9532 - val_loss: 0.1735 - val_accuracy: 0.9360\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1257 - accuracy: 0.9582 - val_loss: 0.1867 - val_accuracy: 0.9333\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1186 - accuracy: 0.9597 - val_loss: 0.1673 - val_accuracy: 0.9354\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1126 - accuracy: 0.9617 - val_loss: 0.1822 - val_accuracy: 0.9364\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1062 - accuracy: 0.9644 - val_loss: 0.1675 - val_accuracy: 0.9355\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1017 - accuracy: 0.9660 - val_loss: 0.1768 - val_accuracy: 0.9352\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0970 - accuracy: 0.9678 - val_loss: 0.1597 - val_accuracy: 0.9376\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0934 - accuracy: 0.9703 - val_loss: 0.1584 - val_accuracy: 0.9379\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0937 - accuracy: 0.9694 - val_loss: 0.1840 - val_accuracy: 0.9294\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0914 - accuracy: 0.9706 - val_loss: 0.1797 - val_accuracy: 0.9377\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0848 - accuracy: 0.9726 - val_loss: 0.1701 - val_accuracy: 0.9325\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0819 - accuracy: 0.9730 - val_loss: 0.2313 - val_accuracy: 0.9314\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0802 - accuracy: 0.9739 - val_loss: 0.1737 - val_accuracy: 0.9323\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "history = model.fit([X_train_text_tf, X_train_num_tf], y_train_tf, epochs=50, verbose=1, validation_data=([X_test_text_tf, X_test_num_tf], y_test_tf), callbacks=[early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      4000\n",
      "           1       0.96      0.92      0.94      4000\n",
      "\n",
      "    accuracy                           0.94      8000\n",
      "   macro avg       0.94      0.94      0.94      8000\n",
      "weighted avg       0.94      0.94      0.94      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.predict([X_test_text_tf, X_test_num_tf])\n",
    "mean = result.mean()\n",
    "std = result.std()\n",
    "normolized_result = (result - mean) / std\n",
    "normolized_result = 1 / (1+np.exp(-normolized_result))\n",
    "print(classification_report(y_test_tf, (normolized_result.flatten() >= 0.5).astype('int') ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raychannudam/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/sentimental.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump({\n",
    "    'config': vectorizer.get_config(),\n",
    "    'weights': vectorizer.get_weights()\n",
    "}, open(\"vectorizers/vectorizer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8000, 30), dtype=int64, numpy=\n",
       "array([[   7,   19,    2, ...,    0,    0,    0],\n",
       "       [3197,  639,   46, ...,    0,    0,    0],\n",
       "       [2985,    7,   17, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 371,  210,    9, ...,    0,    0,    0],\n",
       "       [  56,   13,    4, ...,    0,    0,    0],\n",
       "       [  38,   26,   68, ...,    0,    0,    0]])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_text_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        3.21887582],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        4.02535169],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        4.29045944],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        3.93182563],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        3.40119738],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        3.4657359 ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_num_tf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
